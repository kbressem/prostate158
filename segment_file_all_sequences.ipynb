{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prostate158.transforms import get_base_transforms\n",
    "from prostate158.utils import load_config\n",
    "from prostate158.model import get_model\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torch\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('tests/config/config_all_sequences.yaml') # change to 'tumor.yaml' for tumor segmentation\n",
    "transforms = Compose(get_base_transforms(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config)\n",
    "model.load_state_dict(torch.load('./models_saved/anatomy_all_sequences.pt'), strict=False)\n",
    "model.to(device=device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = transforms({'t2': './tests/input/picai/10000_1000000_0000.nii.gz', 't2_anatomy_reader1': './tests/input/picai/10000_1000000.nii.gz', 'adc': './tests/input/picai/10000_1000000_0001.nii.gz', 'dwi': './tests/input/picai/10000_1000000_0002.nii.gz'})\n",
    "image_t2w = images['t2'].to(device=device).unsqueeze(0)\n",
    "image_adc = images['adc'].to(device=device).unsqueeze(0)\n",
    "image_dwi = images['dwi'].to(device=device).unsqueeze(0)\n",
    "images_all_sequences_input = torch.cat((image_t2w, image_adc, image_dwi), dim=1)  \n",
    "input = torch.cat([images_all_sequences_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    roi_size = (256, 256, 256)\n",
    "    sw_batch_size = 4\n",
    "    val_outputs = sliding_window_inference(input, roi_size, sw_batch_size, model, overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256, 115])\n",
      "torch.Size([1, 256, 256, 115])\n",
      "torch.Size([1, 256, 256, 115])\n"
     ]
    }
   ],
   "source": [
    "print(images['t2_anatomy_reader1'].shape)\n",
    "print(images['t2'].shape)\n",
    "print(torch.argmax(val_outputs, dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d2cc2950de441290e56567a0a49470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=57, description='index', max=114), Output()), _dom_classes=('widget-inteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(index)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# swap 1s and 2s in label image\n",
    "temp_value = 999\n",
    "images[\"t2_anatomy_reader1\"][images[\"t2_anatomy_reader1\"] == 1] = temp_value\n",
    "images[\"t2_anatomy_reader1\"][images[\"t2_anatomy_reader1\"] == 2] = 1\n",
    "images[\"t2_anatomy_reader1\"][images[\"t2_anatomy_reader1\"] == temp_value] = 2\n",
    "\n",
    "def plot(index):\n",
    "    plt.figure(\"check\", figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(f\"image\")\n",
    "    plt.imshow(image_t2w[0, 0, :, :, index].cpu())\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(f\"label\")\n",
    "    plt.imshow(images[\"t2_anatomy_reader1\"][0, :, :, index])\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(f\"output\")\n",
    "    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, index])\n",
    "    plt.show()\n",
    "\n",
    "shape = image_t2w.shape\n",
    "interact(plot, index=(0, shape[-1] - 1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
